## 1) ONNX Runtime?

**ğŸ’¡ ONNX(Open Neural Network Exchange) ë€?**

- ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì„œë¡œ ë‹¤ë¥¸ í”„ë ˆì„ì›Œí¬ ê°„ì— ì„œë¡œ ì˜®ê¸¸ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. ONNXëŠ” ëª¨ë¸ì„ ì¤‘ê°„ ê³„ì¸µ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³  ëª¨ë¸ì„ ì‹¤í–‰í•˜ëŠ” ë° í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- ê°„ëµíˆ ë§í•´, ë‹¤ì–‘í•œ í”Œë«í¼ í™˜ê²½(Java, JS, C, C#, C++)ì—ì„œ í™˜ê²½ì— ì œì•½ ì—†ì´ êµ¬í˜„ëœ â€˜ML ëª¨ë¸â€™ì„ í˜¸ì¶œí•˜ê³  ìˆ˜í–‰í•˜ì—¬ ìˆ˜í–‰ ê²°ê³¼ ê°’ì„ ë°˜í™˜ë°›ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

**ğŸ’¡Â ONNX Runtime ì´ë€?**

- **ONNX ëª¨ë¸ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì—”ì§„ì…ë‹ˆë‹¤. ONNX ëª¨ë¸ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•´ ONNX ëŸ°íƒ€ì„ì€ ë¹ ë¥¸ ì¶”ë¡ ì„ ìœ„í•œ ìµœì í™”ëœ ì»¤ë„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.**
- ë˜í•œ, ONNX Runtimeì€ CPU, GPU ë° ë”¥ëŸ¬ë‹ ê°€ì†ê¸°(DNNL, NNAPI, OpenVINO)ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
- ë”°ë¼ì„œ, ONNX Runtimeì€ ONNX ëª¨ë¸ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ìµœì í™”ëœ ëŸ°íƒ€ì„ í™˜ê²½ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    [[RN] ONNX(Open Neural Network Exchange) ì´í•´í•˜ê¸° -1: React Native í™œìš©](https://adjh54.tistory.com/203)
    

## 2) ëª¨ë¸ ë³€ê²½ : pth to onnx file

### 2.1 pth file

> **ChatGPT**
> 
> 
> **`model.pth`** íŒŒì¼ì€ ì¼ë°˜ì ìœ¼ë¡œ ë¨¸ì‹  ëŸ¬ë‹ ë° ë”¥ ëŸ¬ë‹ ëª¨ë¸ì„ ì €ì¥í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” íŒŒì¼ì…ë‹ˆë‹¤. "pth"ëŠ” ì—¬ê¸°ì„œ "PyTorch"ë¥¼ ì˜ë¯¸í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.
> 
> PyTorchëŠ” íŒŒì´ì¬ ê¸°ë°˜ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ ë¨¸ì‹  ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ë¡œ, ì‹ ê²½ë§ì„ êµ¬ì¶•í•˜ê³  í›ˆë ¨ì‹œí‚¤ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. **`.pth`** í™•ì¥ìë¥¼ ê°€ì§„ íŒŒì¼ì€ ì£¼ë¡œ PyTorch ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜(weight)ì™€ êµ¬ì¡°ë¥¼ ì €ì¥í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
> 
> ë”°ë¼ì„œ **`model.pth`** íŒŒì¼ì„ ë³´ë©´, ê·¸ ì•ˆì—ëŠ” íŠ¹ì • ëª¨ë¸ì˜ í•™ìŠµëœ ê°€ì¤‘ì¹˜(weight)ê°€ ì €ì¥ë˜ì–´ ìˆì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì´ ê°€ì¤‘ì¹˜ëŠ” í•´ë‹¹ ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ (inference)ì´ë‚˜ ì¶”ê°€ì ì¸ í›ˆë ¨ì„ ìˆ˜í–‰í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> 

### **2.2. Pth_to_Onnx.py**

```python
from Anal_lib.utils import load_json, make_dir
import AI_lib.utils as ai_utl 
import os
import json
import numpy as np
import argparse
import torch.onnx 
import torch.nn as nn
import torch.nn.functional as F

arg_parser = argparse.ArgumentParser(description='pre-processing for PL2Map dataset')
arg_parser.add_argument('--single_uid_num', type=int, default=0, 
						help='Input single uid number to evaluate')
arg_parser.add_argument('--eval_single_uid', type=int, default=0, choices=[0,1], 
						help='Evaluate single uid or not')
arg_parser.add_argument('--top_app', type=int, default=5, 
						help='It must match with training top_app')
args, _ = arg_parser.parse_known_args()
ori_number_top_app = args.top_app

# pth model ìƒì„±ì‹œì— ì‚¬ìš©í•œ ë™ì¼í•œ Network ì‚¬ìš©
class Network(nn.Module):
	def __init__(self):
		super(Network, self).__init__()
		self.lr1 = nn.Linear(input_dim, 25)
		self.lr2 = nn.Linear(25, 50)
		self.lr3 = nn.Linear(50, 25)
		self.lr4 = nn.Linear(25, output_dim)
	def forward(self, x):
		x = F.relu(self.lr1(x))
		x = F.relu(self.lr2(x))
		x = F.relu(self.lr3(x))
		x = self.lr4(x)
		return x

#Function to Convert to ONNX 
def Convert_ONNX(): 

    # set the model to inference mode 
    model.eval() 

    # Let's create a dummy input tensor  
    dummy_input = torch.randn(1, input_dim, requires_grad=True)	

    make_dir("pre-train-onnx")
    # Export the model	
    torch.onnx.export(model,         # model being run 
         dummy_input,       # model input (or a tuple for multiple inputs) 
         "pre-train-onnx/model" + str(uid) + ".onnx",       # where to save the model  
         export_params=True,  # store the trained parameter weights inside the model file 
         opset_version=10,    # the ONNX version to export the model to 
         do_constant_folding=True,  # whether to execute constant folding for optimization 
         input_names = ['modelInput'],   # the model's input names 
         output_names = ['modelOutput'], # the model's output names 
         dynamic_axes={'modelInput' : {0 : 'batch_size'},    # variable length axes 
                                'modelOutput' : {0 : 'batch_size'}}) 
    print(" ") 
    print("Model has been converted to ONNX : model" + str(uid) + ".onnx")

# MAIN
# number of features (len of X cols)
input_dim = 3
# number of hidden layers
hidden_layers = [25, 50, 25]
# number of classes (unique of y)
output_dim = 5

num_uids = ai_utl.count_files_in_directory("processed_uids/data")
for uid in range(num_uids):
    number_top_app = ori_number_top_app
    if args.eval_single_uid:
        uid = args.single_uid_num

    
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì²´í¬
    if not os.path.exists(f'processed_uids/data/{uid}.txt'):
        continue  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë£¨í”„ì˜ ë‹¤ìŒ ë°˜ë³µìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.

    # íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ JSON ë°ì´í„° ë¡œë“œ
    with open(f'processed_uids/data/{uid}.txt', 'r') as file:
        data = load_json(f'processed_uids/data/{uid}.txt')

    length_data = len(data)
    if length_data < 10:
    	# skip uid with less than 10 data samples
        continue
    list_of_apps = []
    for i in data:
        if i[1] not in list_of_apps:
            list_of_apps.append(i[1])

    print("Number of Sample is: {}".format(length_data))
    output_dim = len(list_of_apps)
    print(f"Number of Classes is {output_dim}")
    path = "pre-train/model"+str(uid)+".pth" 

    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì²´í¬
    if not os.path.exists(path):
        continue  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë£¨í”„ì˜ ë‹¤ìŒ ë°˜ë³µìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.

    # Let's load the model we just created and test the accuracy per label 
    model = Network()

    # model.load_state_dict(torch.load(path), strict=False) 
    model.load_state_dict(torch.load(path), strict=False) # ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” í‚¤ë¥¼ ë¬´ì‹œí•˜ê¸° ìœ„í•´ strict=False ì‚¬ìš©

    # Conversion to ONNX 
    Convert_ONNX()
    if args.eval_single_uid:
        break

print("--- DONE ---")
```

```bash
// Conda ì‹¤í–‰ í•´ì•¼í•¨. (README.md ì°¸ê³ )
$ python Pth_to_Onnx.py --eval_single_uid 0 --top_app 5
```

## 3) Android App êµ¬í˜„

### 3.1 Gradle ì„¤ì •
ì°¸ê³  : [Install ONNX Runtime](https://onnxruntime.ai/docs/install/#install-on-web-and-mobile) 
1. build.gradle(:app) ì— dependencies ì¶”ê°€

![image](https://github.com/SubingJeong/Studying/assets/74831049/77751514-a6e4-471a-8828-fc4138410c68)


```groovy
dependencies {
    implementation 'com.microsoft.onnxruntime:onnxruntime-android:latest.release'
}
```

1. Import

```java
import ai.onnxruntime.*;
```

1. Sample code

```java
import ai.onnxruntime.*;

public class MainActivity extends AppCompatActivity {

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);

        // ONNX Runtime í™˜ê²½ ì„¤ì •
        OrtEnvironment env = OrtEnvironment.getEnvironment();

        try {
            // ëª¨ë¸ ë¡œë“œ
            String modelPath = getExternalFilesDir(null) + "/model.onnx";
            OnnxTensor modelTensor = OnnxTensor.createTensorFromModelFile(modelPath);
            

            // TODO: ì‹¤ì œ ì…ë ¥ ë°ì´í„°ë¡œ ì±„ìš°ê¸°
            // ì…ë ¥ ë°ì´í„° ìƒì„± (ì´ ì˜ˆì‹œì—ì„œëŠ” ë¬´ì‘ìœ„ ê°’ìœ¼ë¡œ ìƒì„±)
            float[] inputData = new float[224 * 224 * 3];
            
            // ONNX ëª¨ë¸ ì‹¤í–‰
            OnnxTensor inputTensor = OnnxTensor.createTensor(env, inputData);
            OnnxTensor outputTensor = env.run(modelTensor, new String[]{"output"});
            
            // ê²°ê³¼ ì¶œë ¥ (ì´ ì˜ˆì‹œì—ì„œëŠ” ë‹¨ìˆœíˆ ì¶œë ¥ íƒ€ì…ë§Œ ì¶œë ¥)
            System.out.println(outputTensor.getInfo().getType());
        } catch (OrtException e) {
            e.printStackTrace();
        }
    }
}

```
